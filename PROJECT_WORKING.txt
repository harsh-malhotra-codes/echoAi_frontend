Project Working Explanation
===========================

This document explains how the EchoAI Chatbot project works, including the flow of input processing and output generation.

Overview
--------
The EchoAI Chatbot is a web application that allows users to chat with an AI powered by Google Gemini. It consists of a React frontend for the user interface and a Node.js/Express backend for handling API requests and AI interactions.

Architecture
------------
- Frontend: React application with components for landing page, chat interface, etc.
- Backend: Express server that communicates with Google Gemini AI API
- No database: Chat history is not persisted (currently commented out in code)

Input Processing Flow
---------------------

1. User Input Collection
   - User types a message in the chat input field on the frontend
   - The message is captured through React state management in the Chat component

2. Frontend to Backend Communication
   - When user submits the message (e.g., by pressing Enter or clicking send)
   - Frontend makes a POST request to the backend endpoint: /api/chat
   - Request body contains: { "message": "user's typed message" }
   - Uses fetch API with JSON content-type

3. Backend Request Handling
   - Express server receives the POST request at /api/chat
   - Middleware (express.json()) parses the JSON body
   - Extracts the 'message' field from req.body
   - Validates that message is provided (returns 400 if not)

4. AI Processing
   - Backend initializes GoogleGenerativeAI with API key from environment variables
   - Uses the 'gemini-1.5-flash' model
   - Calls model.generateContent(message) with the user's message
   - Waits for AI to generate a response
   - Extracts the text response from the AI result

5. Response Generation
   - Backend creates a JSON response: { "response": "AI generated text" }
   - Sends HTTP 200 response with the JSON
   - If any error occurs (AI API failure, etc.), returns HTTP 500 with error message

6. Frontend Response Handling
   - Frontend receives the JSON response
   - Extracts the 'response' field
   - Updates the chat UI to display the AI's response
   - Chat history is maintained in React state (not persisted)

Error Handling
--------------
- If message is missing: 400 Bad Request
- If AI API fails: 500 Internal Server Error
- Network errors are handled by frontend (though not explicitly shown in current code)

Key Technologies
----------------
- Frontend: React, CSS (with Tailwind), JavaScript
- Backend: Node.js, Express.js
- AI: Google Gemini AI API
- Communication: REST API with JSON

Current Limitations
-------------------
- No chat history persistence (database code is commented out)
- No user authentication
- Single conversation thread (no multi-user support)
- No rate limiting or API usage monitoring

Future Enhancements
-------------------
- Add database integration for chat history
- Implement user sessions
- Add conversation threading
- Improve error handling and user feedback

How to Run the Project
----------------------

Prerequisites
- Node.js (version 14 or higher)
- Git
- Google Gemini API key (get from Google AI Studio)

Setup Steps

1. Clone or download the project
2. Open terminal in the project root directory

Backend Setup:
3. Navigate to backend: `cd echoai-chatbot/backend`
4. Install dependencies: `npm install`
5. Create .env file: Copy .env.example to .env and add your GEMINI_API_KEY
6. Start backend server: `npm run dev`
   - Server will run on http://localhost:5000

Frontend Setup (in a new terminal):
7. Navigate to frontend: `cd echoai-chatbot/frontend`
8. Install dependencies: `npm install`
9. Start frontend: `npm start`
   - App will open at http://localhost:3000

Usage:
- Open http://localhost:3000 in your browser
- Type messages in the chat interface
- AI responses will appear in real-time
